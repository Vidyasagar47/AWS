import boto3

# Replace these values with your own AWS credentials and region
AWS_ACCESS_KEY_ID = 'YOUR_ACCESS_KEY_ID'
AWS_SECRET_ACCESS_KEY = 'YOUR_SECRET_ACCESS_KEY'
AWS_REGION = 'YOUR_AWS_REGION'

# Initialize the AWS service clients
ec2_client = boto3.client('ec2', aws_access_key_id=AWS_ACCESS_KEY_ID, aws_secret_access_key=AWS_SECRET_ACCESS_KEY, region_name=AWS_REGION)
s3_client = boto3.client('s3', aws_access_key_id=AWS_ACCESS_KEY_ID, aws_secret_access_key=AWS_SECRET_ACCESS_KEY, region_name=AWS_REGION)

def list_ec2_instances():
    # List all EC2 instances in your account
    response = ec2_client.describe_instances()
    for reservation in response['Reservations']:
        for instance in reservation['Instances']:
            print(f"Instance ID: {instance['InstanceId']}, State: {instance['State']['Name']}")

def create_s3_bucket(bucket_name):
    # Create an S3 bucket with the given name
    response = s3_client.create_bucket(Bucket=bucket_name)
    print(f"S3 bucket '{bucket_name}' created successfully.")

def upload_file_to_s3(bucket_name, file_path, object_key):
    # Upload a file to the specified S3 bucket with the given object key
    s3_client.upload_file(file_path, bucket_name, object_key)
    print(f"File '{file_path}' uploaded to '{bucket_name}' with key '{object_key}'.")

# Example usage
if __name__ == "__main__":
    # List EC2 instances
    print("List of EC2 Instances:")
    list_ec2_instances()

    # Create an S3 bucket
    bucket_name = "your-unique-bucket-name"
    create_s3_bucket(bucket_name)

    # Upload a file to the S3 bucket
    file_path = "path/to/your/file.txt"
    object_key = "file.txt"
    upload_file_to_s3(bucket_name, file_path, object_key)
